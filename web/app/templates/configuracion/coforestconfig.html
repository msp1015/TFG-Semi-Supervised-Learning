{% extends "configuracion/base_config_inductivos.html" %} {% from "macros.html"
import selector %} {% block parametros %}

<div class="mb-3">
  {{ form.n_arboles.label }} {{ form.n_arboles(class_="form-control") }}
</div>
<div class="mb-3">
  {{ form.theta.label }}
  <div class="d-flex">
    {{ form.theta(class_="form-range w-75",
    oninput="actualizarBadgePorcentaje(this.value,'p_th_badge')",
    disabled=False) }}
    <span id="p_th_badge" class="badge bg-primary px-3 mx-auto">75%</span>
  </div>
</div>
<div class="title-mulish text-bold">
  {{ gettext("Decision Tree parameters") }}
</div>
<div class="parametros" id="parametros"></div>
{% endblock %} {% block form_scripts %}
<script>
  const div_parametros= document.querySelector('#parametros');

  const todos_parametros = {{ parametros|tojson }};
  // Para reutilizar codigo se pone "clasificador1" como nombre del select (aunque solo se usen arboles de decision)
  generarFormParametros("DecisionTreeClassifier", div_parametros, "clasificador1");
</script>
{% endblock %} {% block explicaciones %}
<p>
  {{ gettext('This technique is based on the idea of using multiple classifiers
  (decision trees, in this case), which are iteratively trained with an initial
  set of labeled data. As the algorithm progresses, each tree attempts to
  classify the unlabeled data, and the most confident predictions are added to
  the training set as if they were real labels. This process of "mutual
  teaching" among the classifiers progressively improves the model`s performance
  as more information from the unlabeled data is incorporated. Co-forest
  leverages the diversity among the decision trees to enhance the model`s
  generalization to new or unknown data, making it especially useful in
  scenarios where labels are scarce or expensive to obtain.')}}
</p>
{% endblock %} {% block pseudocodigo %}
<img
  src="{{ gettext('/pseudocodigos/en/CoForest.png') }}"
  width="75%"
  alt="{{ gettext('Co-Forest Pseudocode') }}"
/>
{% endblock %}

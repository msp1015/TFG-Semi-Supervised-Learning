\capitulo{3}{Conceptos teóricos}\label{sec3}

En esta sección se resumirán los conceptos teóricos básicos y necesarios para comprender el trabajo. Principalmente se presentará el aprendizaje automático y luego se profundizará en el aprendizaje semisupervisado.

\section{Aprendizaje automático}
El aprendizaje automático (\textit{Machine Learning} en inglés) es el campo de la inteligencia artificial (IA) que se centra en el uso de datos y en el desarrollo de algoritmos para imitar la manera de aprender de los humanos \cite{ML:ibm}. La esencia radica en la capacidad de los sistemas informáticos para aprender de datos y realizar tareas sin intervención humana directa, si no descubriendo patrones y tendencias en los mismos. A estos sistemas se les conoce como \textbf{modelos}, los cuales pueden mejorar su rendimiento y adaptarse a nuevas situaciones basándose en la experiencia pasada.

Según \cite{ML:DataScientest}, existen cuatro etapas principales en el desarrollo de un modelo. El primer paso consiste en seleccionar y preparar el conjunto de datos (\textit{dataset}) que utilizará el modelo para aprender a resolver el problema para el que se ha diseñado. En el segundo paso se selecciona el algoritmo para ejecutar sobre el \textit{dataset}. Este dependerá del tamaño y el tipo de los datos de entrada y del tipo de problema que se está resolviendo. El tercer paso consiste en entrenar el algoritmo hasta que la mayoría de los resultados sean los esperados. El cuarto y último paso trata de usar el modelo sobre nuevos datos y hacer una evaluación para una posible mejora.

Según los datos que se seleccionen en el primer paso, podemos tener dos ramas distintas en el aprendizaje automático \cite{ML:SisInt}:
\begin{itemize}
	\item \textbf{Predictiva}: también caracterizada por utilizar el aprendizaje supervisado, es decir, datos de entrada etiquetados.
	\item \textbf{Descriptiva}: al contrario, utiliza el aprendizaje no supervisado, con datos de entrada no etiquetados.
\end{itemize}

 
\subsection{Aprendizaje supervisado}
El aprendizaje supervisado es un tipo de aprendizaje automático en el que los modelos son entrenados utilizando conjuntos de datos etiquetados, en los que se basarán las decisiones y predicciones. Los conjuntos de datos contienen ejemplos emparejados de variables de entrada (o características) y de salida (o etiquetas). La esencia de este tipo de aprendizaje se basa en la capacidad del modelo para aprender la relación funcional entre las entradas y las salidas, permitiéndole hacer predicciones precisas sobre nuevos datos no vistos anteriormente~\cite{SL:guide}. De ahí su clasificación como \guillemetleft predictiva\guillemetright ~en la sección anterior.
Dos tareas habituales dentro del aprendizaje supervisado son:
\begin{itemize}
	\item \textbf{Clasificación}: los modelos asignan categorías o clases a las entradas no etiquetadas. Dentro de este tipo se puede encontrar la clasificación binaria y la multi-clase. La primera se ve en un caso como la clasificación de correos electrónicos marcadas como spam o no spam (solo una etiqueta). Y la segunda se puede ver en cualquier ejemplo en el que haya mas de dos clases, como al establecer si un paciente tiene alto, medio o bajo riesgo de muerte ante una operación.
	\item \textbf{Regresión}: es similar a la clasificación, pero en vez de asignar un valor discreto, ahora es un valor continuo. Un ámbito común en el que se suele dar es en la economía, con la predicción de acciones o ventas.
\end{itemize}

También es importante comentar las principales fases que forman este aprendizaje y los posibles problemas o desafíos que pueden surgir, ya que pueden servir para tener en cuenta en los algoritmos concretos a implementar.
En la mayoría de algoritmos que utilizan datos etiquetados, estos se dividen en tres conjuntos: entrenamiento, validación y prueba. El conjunto de entrenamiento se utiliza para ajustar los parámetros del modelo, el conjunto de validación para ajustar los hiperparámetros y prevenir el sobreajuste y el conjunto de prueba apra evaluar el rendimiento final.
El sobreajuste u \textit{\textbf{overfitting}} es uno de los principales problemas del aprendizaje automático y ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento, es decir, los memoriza en vez de generalizar.

\subsection{Aprendizaje no supervisado}
El aprendizaje no supervisado hace referencia a los tipos de problemas en los que se utiliza un modelo para caracterizar o extraer relaciones en los datos.
A diferencia del aprendizaje supervisado, estos algoritmos descubren la estructura implícita de un conjunto de datos utilizando únicamente características de entrada y no clases o categorías. 
Ya que no existen etiquetas en los datos, los métodos no supervisados se utilizan normalmente para crear una representación concisa de los datos, posibilitando la generación de contenido creativo a partir de ellos. Por ejemplo, si tenemos una gran cantidad de fotografías sin clasificar, un modelo no supervisado encontraría relaciones entre las características para poder organizar automáticamente las imágenes en grupos~\cite{USL:guide}.
Principalmente, se pueden clasificar en tres diferentes tareas:
\begin{itemize}
	\item \textbf{Clustering}: segmentación o agrupamiento. Consiste en la identificación de grupos o \textit{clusters} en función de sus similitudes y diferencias. Dentro de este tipo, se puede diferenciar un agrupamiento exclusivo, donde los datos pertenencen a un unico grupo, y un agrupamiento superpuesto, donde los datos pueden perteneces a varias agrupaciones. El ejemplo de las fotografías entra dentro de esta categoría.
	\item \textbf{Reglas de asociación}: utiliza una medida de interés para obtener un conjunto de reglas sólidas que permitan descubrir asociaciones interesantes entre las características de un conjunto de datos. La principal aplicación es el \guillemetleft análisis de cestas de compra\guillemetright, que se usa para determinar los patrones de compra de los clientes en funcion de las relaciones entre productos.
	\item \textbf{Reducción de dimensionalidad}: estos algoritmos buscan reducir la complejidad de un conjunto de datos de alta dimensión a espacios de baja dimensión sin perder propiedades fundamentales de los datos originales~\cite{PCA}. Este tipo de algoritmos se utiliza en la fase de análisis de datos, facilitando la representación gráfica. Se puede ver un ejemplo en la figura \ref{fig:../img/memoria/ML-ReduceDimension.png}.
\end{itemize}

\imagen{../img/memoria/ML-ReduceDimension.png}{Reducción de dimensionalidad}{1} 

En la tabla \ref{supervisado_VS_noSupervisado} se resumen las principales diferencias entre aprendizaje supervisado y no supervisado:
\begin{table}[ht]
	\centering
	\begin{tabular}{@{}p{2.5cm} p{5cm} p{5cm}@{}}
		\toprule
			 & \textbf{Supervisado} & \textbf{No supervisado} \\
		\midrule
		\textbf{Objetivo} & Aproximar una función que asigna entradas a salidas a partir de un conjunto de datos clasificados. & Crear una representación concisa de los datos, posibilitando la generación de contenido creativo a partir de ellos. \\
		\addlinespace[0.5em]
		\textbf{Complejidad} & Simple & Mayor\\
		\addlinespace[0.5em]
		\textbf{Entrada} & Se conoce el número de clases (datos etiquetados). & No se conoce el número de clases (datos no etiquetados). \\
		\addlinespace[0.5em]
		\textbf{Salida} & Genera un valor de salida esperado. & No se tienen valores de salida asociados \\
		\addlinespace[0.5em]
		\textbf{Tareas} & Clasificación, Regresión & Clustering, Reglas de asociación, Reducción de dimensionalidad \\
		\bottomrule
	\end{tabular}
	\caption{Comparación aprendizaje supervisado y no supervisado ~\cite{USL:guide}.}
	\label{supervisado_VS_noSupervisado}
\end{table}
\newpage


\section{Aprendizaje semisupervisado}
Como el nombre sugiere, el aprendizaje semisupervisado se encuentra entre los dos tipos vistos anteriormente. Los algoritmos dentro de esta estrategia se basan en extender cualquiera de los aprendizajes, supervisado o no supervisado, para añadir información adicional que el otro no proporciona~\cite{Intro:SemiSupervised}.

Los métodos de clasificación semi-supervisada intentan utilizar puntos de datos no etiquetados para generar un modelo cuyo rendimiento supere el de los modelos obtenidos al utilizar solo datos etiquetados ~\cite{Engelen:semi-supervised}. 

Por ejemplo, imaginemos que se esta trabajando en la clasificación de imágenes médicas para identificar diferentes tipos de enfermedades. En este caso, consideramos específicamente la detección temprana de ciertos tipos de cáncer a partir de imágenes de tomografías. En un enfoque supervisado, podríamos entrenar un modelo utilizando un conjunto de datos etiquetado que incluye imágenes con diagnósticos de cáncer y sin cáncer. Sin embargo, la obtención de un gran conjunto de datos etiquetado puede ser costosa y consume tiempo. En un escenario de aprendizaje semisupervisado, además de los datos etiquetados, podríamos tener un conjunto de datos mucho más grande que incluye imágenes no etiquetadas. Algunas de estas pueden contener señales sutiles o características asociadas con el cáncer que no han sido previamente etiquetadas.

El modelo de aprendizaje semisupervisado podría analizar estas imágenes no etiquetadas y descubrir patrones que podrian indicar la presencia temprana de cáncer. Por ejemplo, podría aprender a reconocer características microscopicas especificas de las imagenes que no son evidentes para el ojo humano. Cuando se encuentra con nuevas imágenes no etiquetadas que comparten estas características, el modelo podría clasificarlas como indicativas de la presencia de cáncer, incluso si no ha visto exactamente esas características en el conjunto de datos etiquetado.
Existe una condición necesaria en el aprendizaje semisupervisado: la distribución marginal subyacente $p(x)$ sobre el espacio de entrada debe contener información acerca de la distribución posterior $p(x|y)$ ~\cite{Engelen:semi-supervised}. Es decir, la naturaleza de los datos no etiquetados debe contener información útil para inferir las etiquetas correspondientes.
Esta suposición es básica y en la mayoría de los ejemplos se cumple. Aún asi, como la manera de interactuar entre $p(x)$ y  $p(x|y)$ no es siempre la misma, se pueden tomar malas decisiones que conllevarían un rendimiento cada vez peor. Por esta razón, existen tres principales suposiciones que todo conjunto de datos de un algoritmo semisupervisado debe cumplir para funcionar correctamente.
\begin{itemize}
	\item \textit{\textbf{Smoothness assumption}}: traducida como suposición de suavidad, consiste en que para dos puntos $x_{1}$ y $x_{2}$ que están cerca en una región densa, entonces sus correspodientes salidas (o etiquetas) $y_{1}$ y $y_{2}$ deben ser las mismas. Esto es útil sobretodo con datos no eitquetados, ya que por la propiedad transitiva, dos puntos que no estén relativamente cerca, pueden ser de la misma clase.
	\item \textit{\textbf{Low-density assumption}}: esta suposición está definida sobre la distribución de datos de entrada $p(x)$ y dice que el límite de decisión en la clasificación debe pasar antes por un área de poca densidad que por una de mayor densidad. Esto se puede observar en la figura \ref{fig:../img/memoria/Smoothness-LowDensity.png}.

	\imagen{../img/memoria/Smoothness-LowDensity.png}{\textit{Smoothness assumption} y \textit{Low-density assumption}~\cite{Engelen:semi-supervised}}{0.5}
	
	\item \textit{\textbf{Manifold assumption}}: esta suposición afirma que los datos utilizados se encuentran en un \textit{manifold} de baja dimensión incrustado en un espacio de mayor dimensión. En otras palabras, los datos, en lugar de proceder de cualquier parte del espacio, deben proceder de estos \textit{manifolds} de dimensiones más bajas ~\cite{web:assumptions}.
	\imagen{../img/memoria/ManifoldAssumption.png}{\textit{Manifold assumption}~\cite{web:assumptions}}{0.45}
\end{itemize}

En algunas ocasiones, aparece una cuarta suposición: \textit{\textbf{cluster assumption}}. Esta indica que dos datos que pertenecen a un mismo \textit{cluster}, pertenecen también a la misma clase. Se tomará esta suposición como una generalización de las tres anteriores ~\cite{Engelen:semi-supervised}.

\imagen{../img/memoria/ClusterAssumption.png}{\textit{Cluster assumption}~\cite{web:assumptions}}{0.6}

\subsection{Taxonomía}
No hay una clasificación oficial de algoritmos de aprendizaje semisupervisado, pero sí se pueden encontrar aproximaciones teniendo en cuenta las suposiciones en las que estan basadas los algoritmos y en cómo se relacionan con los algoritmos supervisados y no supervisados.
\imagen{../img/memoria/Clasificacion-SemiSupervised}{Clasificación de los diferentes algoritmos que pretenden incorporar datos no etiquetados a métodos de clasificación. Basado en~\cite{Engelen:semi-supervised}}{1}

\subsection{Métodos inductivos}
Los métodos inductivos en aprendizaje semi-supervisado tienen como objetivo construir un clasificador que pueda generar predicciones para cualquier objeto dentro del espacio de entrada. Durante la fase de entrenamiento de este clasificador, se pueden utilizar datos no etiquetados junto con los datos etiquetados disponibles. Una vez que el entrenamiento del modelo se ha completado, las predicciones que el clasificador realiza para nuevos datos son independientes entre sí. Esto significa que el modelo puede generalizar y hacer predicciones sobre nuevos ejemplos que no fueron vistos durante el entrenamiento, basándose en el conocimiento adquirido de los datos etiquetados y no etiquetados utilizados durante el entrenamiento~\cite{Engelen:semi-supervised}.
\begin{itemize}
	\item \textbf{\textit{Wrapper methods}}: Estos métodos inicialmente entrenan clasificadores utilizando únicamente los datos etiquetados. Después, las predicciones generadas por estos clasificadores se utilizan para etiquetar datos no etiquetados adicionales, creando así un conjunto de datos pseudo-etiquetados. El clasificador se vuelve a entrenar con estos datos adicionales, mejorando su capacidad para generalizar a partir de la información combinada de los datos originalmente etiquetados y los pseudo-etiquetados. En este grupo entrarían los cuatro algoritmos implementados en el trabajo anterior.
	\item \textbf{\textit{Unsupervised preprocessing}}: En este enfoque, los métodos no supervisados se utilizan para extraer características útiles, agrupar datos o determinar parámetros iniciales de aprendizaje antes de entrenar el clasificador supervisado. Este preprocesamiento con datos no etiquetados mejora el rendimiento del clasificador supervisado, aprovechando las estructuras y patrones presentes en los datos no etiquetados.
	\item \textbf{\textit{Intrinsecally semi-supervised}}: Estos métodos integran directamente los datos no etiquetados en la función objetivo o en el procedimiento de optimización del modelo de aprendizaje. Al incorporar datos no etiquetados en la función objetivo, se maximiza la información obtenida durante el proceso de aprendizaje, lo que lleva a una mejor generalización y rendimiento del clasificador.
	
\end{itemize}
\subsection{Métodos transductivos} \label{sec3:transductivo}
A diferencia de los métodos inductivos, los métodos transductivos no construyen un modelo para todo el espacio de entrada. En su lugar, su poder predictivo se limita exactamente a los objetos que encuentra durante la fase de entrenamiento. Por lo tanto, los métodos transductivos no tienen fases de entrenamiento y predicción distintas \cite{Engelen:semi-supervised}.

El aprendizaje transductivo puede ahorrar tiempo y es preferible cuando el objetivo se orienta a mejorar nuestro conocimiento sobre el conjunto de datos sin etiquetar. Sin embargo, este enfoque tiene limitaciones, especialmente cuando queremos entender causas y efectos dentro de los datos. Básicamente, aunque el aprendizaje transductivo es útil para hacer inferencias específicas sobre los datos no etiquetados basándose en los datos etiquetados, no es adecuado ni efectivo para estudiar o predecir relaciones causales, es decir, cómo un factor directamente provoca otro. Esto se debe a que el aprendizaje transductivo se centra sólo en los datos presentes durante el entrenamiento y no generaliza más allá de estos~\cite{web:assumptions}.
Los métodos transductivos suelen definir un grafo sobre todos los puntos de datos, tanto etiquetados como no etiquetados, codificando la similitud entre pares de puntos de datos con aristas posiblemente ponderadas. Para definir más en detalle el aprendizaje semisupervisado basado en grafos (GSSL por sus siglas en inglés), se ha utilizado como base los conceptos del artículo~\cite{Engelen:semi-supervised} y para detallar más información se ha utilizado uno de los artículos más actualizados en este ámbito hasta la fecha~\cite{GSSL:review}. Ambos coinciden en que estos algoritmos se dividen en dos pasos: creación del grafo y fase de inferencia (se refiere al proceso de asignar etiquetas o categorías a los nodos no etiquetados en un grafo utilizando la información de los nodos etiquetados y la estructura del grafo).
\subsubsection{Construccion de grafos}
En el contexto del aprendizaje semi-supervisado basado en grafos (GSSL), la construcción del grafo es un paso crítico. Durante esta fase, se crea un grafo que representa todos los datos disponibles, tanto etiquetados como no etiquetados. Los nodos representan muestras y las aristas ponderadas reflejan la similitud entre pares de muestras. Existen varios métodos para construir estos grafos, que pueden clasificarse en métodos no supervisados y supervisados.
\begin{itemize}
	\item \textbf{Métodos no supervisados}: Los métodos no supervisados ignoran la información de las etiquetas durante la construcción del grafo. Entre los enfoques más populares se encuentran:
	\begin{itemize}
		\item \textbf{\textit{$k$-Nearest Neighbours}}: cada nodo se conecta a sus $k$ vecinos más cercanos según alguna medida de distancia. Puede tener dos variantes: \textit{symmetric $k$ nearest neighbours}, que construye una arista si $i$ o $j$ estan en el ``vecindario'' de $k$ y mutual $k$-nearest neighbours que la construye si ambos están en la $k$ vecindad del otro, es decir, la relación es bidireccional.
		\item \textbf{\textit{$b$-Matching}}: Asegura que cada nodo tenga exactamente $b$ vecinos, lo que resulta en un grafo regular donde las etiquetas se propagan de manera equilibrada.
	\end{itemize}
	\item \textbf{Métodos supervisados}: Estos métodos utilizan la información de las muestras etiquetadas para refinar el grafo durante su construcción. Algunos ejemplos son:
	\begin{itemize}
		\item \textbf{\textit{GBILI (Graph-based on Informativeness of Labeled Instances)}} [\ref{sec3:gbili}]: Utiliza información de las etiquetas para crear grafos más precisos y robustos.
		\item \textbf{\textit{RGCLI (Robust Graph that Considers Labeled Instances)}} [\ref{sec3:rgcli}]: Optimiza la construcción del grafo para mejorar la precisión en tareas de inferencia posteriores.
	\end{itemize}
\end{itemize}

Dentro de esta fase, un proceso importante es pondera el grafo (dar pesos a las aristas). En primer lugar, se construye una matriz de adyacencia completa utilizando una función $k$ y después se obtiene la matriz de pesos $W$ mediante \textit{sparsification}\footnote{Sparsification es el proceso de eliminar elementos menos significativos de una matriz o aristas en un grafo, con el fin de hacer la estructura más esparcida y eficiente en términos de almacenamiento y procesamiento.}. Uno de los métodos más populares y sencillos, y en el que se profundizará en secciones más adelante, consiste en ponderar los enlaces entre los nodos con un 1 si existe relación entre ellos y con un 0 en caso contrario. Ponderar las aristas es crucial ya que refleja la fuerza de las relaciones entre nodos, lo que puede influir significativamente en la propagación de etiquetas y en la precisión final del algoritmo.


\subsubsection{Fase de inferencia}
En la fase de inferencia del aprendizaje semisupervisado basado en grafos (GSSL), se utilizan dos enfoques principales: la regularización en grafos y el \textit{embedding} en grafos. Estos métodos se centran en la propagación de etiquetas desde los nodos etiquetados a los no etiquetados mediante la estructura del grafo construido.
\begin{itemize}
	\item \textbf{Regularización en grafos}: La regularización en grafos busca encontrar una función de predicción que sea lo más cercana posible a las etiquetas conocidas y que mantenga una suavidad en todo el grafo. Esto significa que nodos conectados con una fuerte relación (representada por el peso de los bordes) deberían tener etiquetas similares. Los métodos de regularización en grafos se pueden clasificar en varias categorías:
	\begin{itemize}
		\item \textbf{Propagación de etiquetas (\textit{Label propagation})}: Este método es uno de los más populares para la inferencia de etiquetas en GSSL. Se basa en la idea de que las etiquetas de algunos nodos (semillas) se pueden propagar a los nodos no etiquetados basándose en la similitud representada por el grafo.
		\begin{itemize}
			\item \textbf{Campos Aleatorios Gaussianos (\textit{Gaussian Random Fields})}: Utiliza una función de predicción que debe cumplir con ciertas restricciones para asegurar que los nodos conectados compartan etiquetas similares.
			\item \textbf{Consistencia Local y Global (\textit{Local and Global Consistency)}} [\ref{sec3:LGC}]: Este método extiende el enfoque de GRF a un contexto multiclase y trata de minimizar una función objetivo que penaliza las diferencias entre las etiquetas inferidas y las etiquetas conocidas.
		\end{itemize}
		\item \textbf{Regularización dirigida}: Este enfoque extiende la regularización a grafos dirigidos, utilizando caminos aleatorios para manejar la direccionalidad de los bordes.
		\item \textbf{Regularización de variedad (\textit{Manifold Regularization})}:  Esta técnica aprovecha la geometría intrínseca de los datos.
	\end{itemize}
	\item \textbf{\textit{Embedding} en grafos}: El \textit{embedding} en grafos transforma la información estructural del grafo en un espacio de menor dimensión, facilitando la tarea de inferencia de etiquetas. Este enfoque se divide en tres componentes principales:
	\begin{itemize}
		\item \textbf{Codificador}: ransforma cada nodo del grafo en un vector de características de baja dimensión, preservando la estructura del grafo y la información de los nodos.
		\item \textbf{Decodificador}: Reconstruye la información del grafo a partir de los vectores de características generados por el codificador.
		\item \textbf{Reconstrucción}: El objetivo es minimizar la diferencia entre las medidas de similitud en el grafo original y las predicciones del decodificador.
	\end{itemize}
\end{itemize}

En resumen, los métodos transductivos en el aprendizaje semi-supervisado basado en grafos ofrecen un enfoque potente y escalable para aprovechar tanto datos etiquetados como no etiquetados. Aunque presentan ciertas limitaciones en la generalización y el estudio de relaciones causales, su capacidad para mejorar el conocimiento sobre conjuntos de datos no etiquetados los hace altamente valiosos en diversas aplicaciones.
\clearpage
\subsection{\textit{ Graph-based on informativeness of
labeled instances} (GBILI)}\label{sec3:gbili}
El algoritmo \textit{\textbf{GBILI}} o Construcción de Grafos Basada en la Informatividad de Instancias Etiquetadas~\cite{gbili} es un método de construcción de grafos para el aprendizaje semisupervisado. Su principal característica es que se basa en la informatividad de las instancias etiquetadas para relacionar nodos dentro del grafo, pudiendo aprovechar después esta conectividad para predecir las etiquetas de los datos no etiquetados. Se utilizan los métodos de $k$-vecinos más cercanos y  $k$-vecinos más cercanos mutuos para inicializar el grafo. En el pseudocódigo \ref{alg:Gbili}, propuesto en, se puede ver el proceso detallado.

\subsubsection{Metodología}
El algoritmo aprovecha la información de las etiquetas disponibles para priorizar las conexiones entre los vértices, especialmente aquellos que están más cerca de un punto etiquetado, convirtiendo así estos puntos etiquetados en hubs a medida que aumenta el valor de $k$.
Los pasos que sigue son:
\begin{enumerate}
	\item Generación de la Matriz de Distancias: Se crea una matriz de distancias $D$ usando la distancia euclidiana para determinar los $k$ vecinos más cercanos de cada elemento.
	\item Configuración de Parámetros: Se establece el parámetro $k$ con un valor natural y se genera una lista de puntos etiquetados	$L$.
	\item Búsqueda de Vecinos Más Cercanos: Para cada vértice $v_i$, se encuentran sus $k$ vecinos más cercanos.
	\item Determinación de Vecinos Mutuos: Se identifican los $k$ vecinos mutuos para $v_i$.
	\item Cálculo de la Informatividad: Se calcula la suma de las distancias desde $v_i$ a cada elemento de vecinos mutuos y desde estos elementos hasta un punto etiquetado. Se establece una conexión entre $v_i$ y $v_j$ que minimice esta suma. Este aspecto puede verse confuso y por ello se comenta en la sección \ref{sec5:gbili}.
	\item Post-procesamiento del Grafo: Se conectan los componentes aislados mediante una búsqueda en anchura (\textit{BFS}) para encontrar componentes en la red. Los componentes sin puntos etiquetados se conectan con componentes vecinos que tienen puntos etiquetados, limitando el número de nuevas conexiones para evitar una red demasiado densa.
\end{enumerate}

\begin{algorithm}[H]
\scriptsize
	\label{alg:Gbili}
	\KwIn{Conjunto de datos etiquetados $L$, conjunto de datos no etiquetados $U$, número de vecinos más cercanos $K$}
	\KwOut{Grafo $G$}
	\BlankLine
	Generar matriz de distancias $D$ entre todos los puntos de datos\\
	Establecer el parámetro K\\
	\For{$i$=1; $i<|V|$; $i++$}{
		\For{$k$=1; $k<K$; $k++$}{
			\For{$j$=1; $j<|V|$; $j++$}{
				\If{$D(v_i,v_j)$ es el $kNN$}{
					$listakNN(v_i) \leftarrow v_j$
				}
			}
		}
		\For{$j$=1; $j<listakNN(v_i)$; $j++$}{
			\For{$k$=1; $k<K$; $k++$}{
				\If{$D(v_j,v_i)$ es el $kNN$}{
					$listaMutuoskNN(v_i) \leftarrow v_j$
				}
			}
		}
		\For{$j$=1; $j<listaMutuoskNN(v_i)$; $j++$}{
			\For{$l$=1; $l<L$; $l++$}{
				\If{$D(v_i,v_j) + D(v_j, v_i)$ es mínima }{
					$G \leftarrow e_{i,j}$
				}
			}
		}
	}
	$Componentes = BFS(G)$\\
	\For{$i=1$; $i<|V|$; $i++$}{
		\If{$Componentes(v_i) \notin L$}{
			\For{$k=1$;$k<listakNN(v_i)$; $k++$}{
				\If{$Componentes(v_k) \in L$}{
					$G \leftarrow e_{i,k}$
				}
			}
		}
	}
	\Return{$G$}
	\caption{\textit{GBILI}}
\end{algorithm}

Como se comenta en uno de los pasos, hay ciertos puntos en este algoritmo que deben ser comentados para evitar confusión en la implementación. Además, para este trabajo en concreto, el algoritmo sufre ciertas modificaciones (con la misma idea teórica) que se comentan en la sección \ref{sec5:gbili}.
\clearpage
\subsection{\textit{Robust Graph that Considers Labeled Instances} (RGCLI)}\label{sec3:rgcli}
El algoritmo \textbf{\textit{RGCLI}} (Grafo Robusto que Considera Instancias Etiquetadas) es una mejora del método GBILI, diseñado para la construcción de grafos robustos en el aprendizaje semi-supervisado \cite{rgcli}. Este método aprovecha la informatividad de las instancias etiquetadas para generar grafos más eficaces en la propagación de etiquetas, asegurando una mejor representación de la estructura de los datos y optimizando el rendimiento de las tareas de clasificación. GBILI tiene limitaciones significativas, como una alta complejidad temporal cuadrática, lo que dificulta su aplicación en conjuntos de datos grandes. RGCLI mejora GBILI al reducir la complejidad temporal de cuadrática a $O(nklogn)$, o que permite manejar conjuntos de datos grandes de manera más eficiente. Además, RGCLI demuestra matemáticamente que el grafo construido es óptimo para modelar la suposición de suavidad.

El algoritmo original de RGCLI sigue un enfoque optimizado para construir grafos que satisfacen las suposiciones de consistencia del aprendizaje semisupervisado, tanto a nivel local como global. Utiliza hilos para realizar una ejecución concurrente y estructuras poco costosas como \textit{kdtrees}\footnote{<<En ciencias de la computación, un Árbol kd es una estructura de datos de particionado del espacio que organiza los puntos en un espacio euclídeo de k dimensiones, empleando solo planos perpendiculares a uno de los ejes del sistema de coordenadas>>~\cite{eswiki:kdtree}.}. Como se puede observar en el algoritmo~\ref{alg:rgcli}, recibe dos parámetros, $k_e$ y $k_i$ que indican el número de vecinos a encontrar en cada fase del algoritmo. Después de incializar todas las estructuras necesarias, el algoritmo se divide en dos fases:
\begin{enumerate}
	\item \textbf{Búsqueda de vecinos más cercanos}: Se construye un \textit{kdtree} a partir de los datos de entrada y se utiliza para buscar los $k_e$ vecinos más cercanos para cada punto. Además, se almacena información sobre los vecinos etiquetados más cercanos.
	\item \textbf{Construcción del grafo RGCLI}: Se calculan los vecinos mutuos más cercanos (MkNN) y se asignan puntuaciones basadas en las distancias a los vecinos y a los puntos etiquetados. Se establecen conexiones entre los puntos utilizando los $k_i$ vecinos que minimizan las puntuaciones calculadas. La construcción del grafo prioriza las conexiones con puntos cercanos y etiquetados, generando un grafo esparso y eficiente para la propagación de etiquetas.
\end{enumerate}

\begin{algorithm}[H]
\scriptsize
	\label{alg:rgcli}
	\KwIn{número de $k$ vecinos más cercanos $k_e$,
		número de RGCLI vecinos más cercanos $k_i$,
		lista de datos etiquetados $L$,
		\textit{dataset} $X$,
		número de hilos $nt$}
	\KwOut{Grafo $G$}
	\BlankLine
	$V$ $\leftarrow$ vértices a partir de $X$ \\
	$E, W$ $\leftarrow \emptyset$ \\
	$G \leftarrow (V, E, W)$ \\
	$kdtree \leftarrow$ a partir de $X$ \\
	$kNN \leftarrow$ map \\
	$F \leftarrow$ map \\
	$L \leftarrow$ map \\
	$T \leftarrow \{T_i : \bigcup_{i=1}^{nt} T_i = V, \bigcap_{i=1}^{nt} T_i = \emptyset \}$ \\
	\For{$T_i \in T$}{
		$t \leftarrow$ Hilo(SearchKNN($T_i$, $k_e$, $kdtree$, $kNN$, $L$)) \\
		$t$.start() \\
	}
	\For{$T_i \in T$}{
		$t \leftarrow$ Hilo(SearchRGCLI($G_L$, $T_i$, $k_i$, $kNN$, $L$)) \\
		$t$.start() \\
	}
	\Return{$G$}

	\BlankLine
	\SetKwFunction{FSearchKNN}{SearchKNN}
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{\FSearchKNN{$T$, $k_e$, $kdtree$, $kNN$, $L$}}{
		\For{$v_i \in T$}{
			$kNN[v_i] \leftarrow kdtree.query(v_i, k_e)$ \\
			$L[v_i] \leftarrow$ encontrar puntos etiquetados más cercanos en $L$ \\
			$F[v_i] \leftarrow$ encontrar el $k$-ésimo vecino más lejano de $v_i$ \\
		}
	}
	
	\BlankLine
	\SetKwFunction{FSearchRGCLI}{SearchRGCLI}
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{\FSearchRGCLI{$G_L$, $T$, $k_i$, $kNN$, $L$}}{
		\For{$v_i \in T$}{
			$\epsilon \leftarrow$ mapa \\
			\For{$v_j \in kNN[v_i]$}{
				\If{$dist(v_i, v_j) \leq dist(v_j, F[v_j])$}{
					$e \leftarrow (v_j, v_i)$ \\
					$\epsilon[e] \leftarrow dist(v_i, v_j) + dist(v_j, L[v_j])$ \\
				}
			}
		}
		$E^* \leftarrow$ obtener $k_i$ aristas con la menor puntuación de $\epsilon$ \\
		$E \leftarrow E \cup E^*$ \\
		$w(e) \leftarrow 1 \forall e=(v_i, v_j) \in E^*$ \\
	}
	\caption{\textit{RGCLI}}
\end{algorithm}
En resumen, el algoritmo RGCLI mejora significativamente la construcción de grafos para SSL al reducir la complejidad temporal y utilizar instancias etiquetadas de manera efectiva. El uso de \textit{kdtrees} optimiza la búsqueda de vecinos más cercanos, y las fases del algoritmo garantizan la creación de un grafo robusto y esparso que facilita la propagación de etiquetas y mejora el rendimiento del aprendizaje semisupervisado.
\clearpage
\subsection{\textit{Local and Global Consistency}} \label{sec3:LGC}
Este algoritmo aborda el problema general de aprender a partir de grafos, utilizando tanto datos etiquetados como no etiquetados. Dado un conjunto de puntos $X$ y un conjunto de etiquetas $L$, los primeros $l$ puntos tienen etiquetas y los puntos restantes no están etiquetados. El objetivo es predecir las etiquetas de los puntos no etiquetados. Este proceso se conoce como la fase de inferencia en los algoritmos de aprendizaje semi-supervisado basados en grafos (GSSL, por sus siglas en inglés). El algoritmo está fuertemente basado en dos suposiciones fundamentales: 
\begin{itemize}
	\item \textbf{Homogeneidad Local}: Los puntos cercanos tienden a tener la misma etiqueta.
	\item \textbf{Homogeneidad Global}: Los puntos en la misma estructura (como un \textit{cluster}) probablemente tengan la misma etiqueta.
\end{itemize}

La idea principal es que cada punto propague iterativamente su información de etiqueta a sus vecinos hasta que se alcance un estado global estable. El pseudocódigo \ref{alg:LGC} y las aclaraciones siguientes están basados en el artículo~\cite{LGC}.

\begin{itemize}
	\item Crear la matriz de afinidad: Calcula una matriz $W$ que mide la similitud entre cada par de puntos en $X$. Si dos puntos están muy cerca entre sí, su valor en la matriz $W$ será alto. Los valores en la diagonal de la matriz (que corresponden a la similitud de un punto consigo mismo) se establecen en cero.
	\item Normalizar\footnote{\textbf{Normalizar} es un proceso en el que se ajustan los valores de una matriz o conjunto de datos para que sean más comparables y manejables} la matriz de afinidad: Ajusta la matriz	$W$ para obtener una nueva matriz $S$. Esto es necesario para asegurar que los valores se propaguen correctamente en los pasos siguientes.
	\item Propagar la información de etiquetas: Comienza con una matriz inicial $F$ que contiene las etiquetas conocidas. Repite un proceso en el que cada punto actualiza su etiqueta basada en las etiquetas de sus puntos vecinos y sus etiquetas iniciales. Este proceso se repite hasta que las etiquetas dejan de cambiar significativamente.
	\item Asignar etiquetas finales: Una vez que la propagación de etiquetas ha convergido (ya no cambia mucho), asigna a cada punto la etiqueta de la clase con la que tiene mayor afinidad. Esto se hace eligiendo la etiqueta que corresponde al valor más alto en la matriz $F$ para cada punto.
\end{itemize}
\begin{algorithm}[H]
\scriptsize
	\caption{Local and Global Consistency}
	\label{alg:LGC}
	\KwIn{Conjunto de puntos $X = \{x_1, \dots, x_l, x_{l+1}, \dots, x_n\} \subseteq {R}^m$, conjunto de etiquetas $L = \{1, \dots, c\}$}
	\KwOut{Etiquetas predichas para los puntos no etiquetados}
	
	\BlankLine
	\textbf{Paso 1: Formar la matriz de afinidad} $W$ \\
	\For{$i=1$ \textbf{to} $n$}{
		\For{$j=1$ \textbf{to} $n$}{
			\If{$i \neq j$}{
				$W_{ij} \leftarrow \exp(-\|x_i - x_j\|^2 / 2\epsilon^2)$
			}
			\Else{
				$W_{ii} \leftarrow 0$
			}
		}
	}
	
	\BlankLine
	\textbf{Paso 2: Construir la matriz} $S = D^{-1/2} W D^{-1/2}$ \\
	$D$ es una matriz diagonal con el elemento $(i, i)$ igual a la suma de la $i$-ésima fila de $W$
	
	\BlankLine
	\textbf{Paso 3: Iterar} $F^{(t+1)} = \alpha S F^{(t)} + (1 - \alpha) Y$ \textbf{hasta la convergencia} \\
	$\alpha$ es un parámetro $\in (0, 1)$
	
	\BlankLine
	\textbf{Paso 4: Asignar etiquetas} \\
	Deja que $F^*$ denote el límite de la secuencia $\{F^{(t)}\}$ \\
	\For{$i=1$ \textbf{to} $n$}{
		$y_i \leftarrow \arg\max_{j \leq c} F^*_{ij}$
	}
	
	\Return{Etiquetas predichas para los puntos no etiquetados}
	
\end{algorithm}

Este algoritmo, como se ha podido llegar a observar, podría no usar directamente la unión física entre nodos del grafo, es decir, no utilizar el paso anterior de construcción del grafo, y aún así, funcionar correctamente, ya que dispondría de la información que da la matriz de distancias. Por ello, para el interés de este trabajo, es necesario buscar una manera de utilizar esta información, la cual se comenta en la seccion \ref{sec5:LGC}.
\clearpage
\section{Ensembles}
Los sistemas basados en \textit{ensembles} se refieren al proceso de combinar las opiniones de un conjunto de modelos diferentes para tomar una decisión final. Se ha descubierto que los \textit{ensembles} pueden producir resultados más favorables en comparación con los sistemas de un solo experto en una amplia gama de aplicaciones. La creación de un \textit{ensemble} implica generar componentes individuales del sistema y luego combinar sus clasificaciones. En este contexto, se destacan dos técnicas principales: \textit{bagging} y \textit{boosting}~\cite{ensembles}.

\subsection{Bagging}
El \textit{Bagging}, o \textit{Bootstrap Aggregating}, es una técnica que mejora la estabilidad y precisión de los algoritmos de aprendizaje automático. Funciona mediante la creación de múltiples versiones de un predictor y utilizando estos para obtener un conjunto agregado. Se generan diferentes conjuntos de entrenamiento, cada uno mediante muestreo con reemplazo del conjunto original, y se entrena un modelo en cada uno de ellos. La decisión final se toma por mayoría de votos para clasificación o el promedio en regresión. Esta técnica es particularmente efectiva con modelos que tienen alta varianza.
\imagen{../img/memoria/bagging.png}{Concepto de bagging \cite{web:boostingvsbaging}}{1}

\subsection{Boosting}
El \textit{Boosting} es un enfoque que construye secuencialmente un conjunto de modelos; cada nuevo modelo se enfoca en corregir los errores cometidos por los modelos anteriores. AdaBoost, uno de los algoritmos de \textit{boosting} más conocidos, ajusta los pesos de las instancias incorrectamente clasificadas para que modelos posteriores se enfoquen más en ellas. A diferencia del \textit{bagging}, el \textit{boosting} puede aumentar el riesgo de sobreajuste si el conjunto de datos es ruidoso, pero generalmente produce modelos más precisos.
\imagen{../img/memoria/boosting.png}{Concepto de boosting \cite{web:boostingvsbaging}}{1}


\subsection{\textit{Co-Forest}}
El co-forest es una versión semisupervisada del método de clasificación \textit{random forest}, diseñado para usar tanto datos etiquetados como no etiquetados. En este método, los árboles de decisión (que conforman el \textit{random forest}) se entrenan en un proceso iterativo utilizando subconjuntos de datos etiquetados junto con pseudo-etiquetas seleccionadas de los datos no etiquetados basadas en su alta confiabilidad. La confiabilidad de estas pseudo-etiquetas es evaluada por todos los árboles del ensemble excepto el árbol que está siendo entrenado en ese momento, denominado el conjunto concomitante. El entrenamiento continúa hasta que se alcanza un criterio de parada definido como el \textit{Out Of Bag Error} (OOBE), que mide el error de predicción del conjunto concomitante usando solo aquellos árboles que no incluyeron una muestra específica de los datos etiquetados en su entrenamiento~\cite{IEEE:CoForest}. A continuación se muestra el pseudocódigo y una explicación más extensa:
\begin{algorithm}
\scriptsize
	\label{alg:Co-Forest}
	\KwIn{Conjunto de datos etiquetados $L$, conjunto de datos no etiquetados $U$, número de árboles $n$, umbral de confianza $\theta$, sumatorio de confianzas inicial $W_{inicial}$ y parámetros para los árboles de decision $p$}
	\KwOut{\textit{Ensemble} de árboles entrenado $H$}
	\BlankLine
	\For{$i$ = 0, ..., $n-1$}{
		$L_{i} \leftarrow$ \textit{Bootstrap}($L$)\\
		$h_i$ = EntrenarArbol($L_{i}$, $p$)\\
		$\hat{e}_{i,t} \leftarrow 0.5$\\
		$W_{i,0} \leftarrow$ $W_{inicial}$  \\
	}
	
	$t \leftarrow 0$\\
	\While(){Algún árbol reciba pseudo-etiquetas}{
		$t \leftarrow t + 1$\\
		
		\For{$i$ = 0, ..., $n-1$}{
			$\hat{e}_{i,t} \leftarrow$ EstimateError($H_i, L$)\\
			$L'_{i,t} \leftarrow \emptyset$\\
			
			\If{$\hat{e}_{i,t} < \hat{e}_{i,t-1}$}{
				$W_{max} = \hat{e}_{i,t-1}W_{i,t-1}/\hat{e}_{i, t}$\\
				$U'_{i,t} \leftarrow$ Submuestrear($U, H_i, W_{max}$)\\
				$W_{i,t} \leftarrow 0$
				
				\ForEach{$x_j \in U'_{i,t}$}{
					
					\If{\text{Confianza}($H_i, x_j$) > $\theta$}{
						$L'_{i,t} \leftarrow L'_{i,t} \cup {x_j, H_i(x_j)}$\\
						$W_{i,t} \leftarrow W_{i,t} + \text{Confianza}(H_i, x_j)$
					}
				}
			}
		}
		\For{$i$ = 0, ..., $n-1$}{
			\If{$(e_{i,t} * W_{i,t} < e_{i, t-1} * W_{i, t-1})$}{
				$h_i$ = ReentrenarArbol($L_{i} \cup L'_{i,t}$)\\
			}
		}
	}
	\Return{$H$}
	\caption{\textit{Co-Forest}}
\end{algorithm}

Inicialización de Variables:
\begin{itemize}
	\item Cada árbol del \textit{ensemble}, $h_i$, se inicializa entrenándolo con una muestra \textit{bootstrap} del conjunto etiquetado $L$.
	\item Se establece un error estimado inicial, $\hat{e}_{i,t}$, a 0.5 para cada árbol.
	\item Se asigna el sumatorio de confianzas inicial a cada árbol. Basado en el estudio comentado en la sección \ref{sec5:coforest}.
\end{itemize}

Proceso iterativo:
\begin{itemize}
	\item El bucle continúa mientras al menos un árbol pueda recibir nuevas pseudo-etiquetas para entrenamiento.
	\item Se estima el error actual (\textit{OOBE}) del árbol usando el conjunto etiquetado.
	\item Se inicializa un conjunto temporal $L'_{i,t}$ para acumular nuevas pseudo-etiquetas aceptadas.
	\item Si el error estimado del árbol mejora (disminuye respecto a la iteración anterior), se procede a submuestrear el conjunto no etiquetado $U$ basándose en el peso máximo $W_{max}$, que ajusta la cantidad de datos a submuestrear en función de la mejora en el error.
	\item Cada dato submuestreado se evalúa, y si la confianza en su pseudo-etiqueta supera el umbral $\theta$, se añade al conjunto temporal $L'_{i,t}$ con su correspondiente pseudo-etiqueta, y se actualiza el sumatorio de confianzas para ese árbol.
\end{itemize}

Reentrenamiento de árboles:
Después de evaluar y potencialmente agregar nuevas pseudo-etiquetas, se decide si reentrenar el árbol. Esto se basa en una comparación del producto de error y sumatorio de confianzas actual contra el de la iteración anterior. Si el producto actual es menor, se procede a reentrenar el árbol incorporando las nuevas pseudo-etiquetas. Esto ayuda a mantener la calidad del modelo y a evitar el sobreajuste.

\section{Métodos de evaluación de algoritmos de Aprendizaje Automático}
La evaluación de algoritmos de \textit{Machine Learning} es fundamental para asegurar su rendimiento y capacidad de generalización. A continuación, se presenta un resumen de los conceptos y métodos más utilizados, siguiendo la guía~\cite{web:crossVal}.
\subsection{\textit{Random Split}}
\textit{Random Split} consiste en muestrear aleatoriamente un porcentaje de datos en conjuntos de entrenamiento, prueba y, preferiblemente, validación. La ventaja de este método es que asegura una representación adecuada de la población original en los tres conjuntos, evitando un muestreo sesgado.

Es importante usar el conjunto de validación en la selección de modelos, como paso intermedio a la evaluación final, para ajustar parámetros en la fase de entrenamiento. El conjunto de prueba, que contiene datos completamente no vistos, se usa para la evaluación final del modelo después de la selección de características y ajuste de parámetros~\cite{web:evaluate}.

\subsection{Validación cruzada}
La validación cruzada es una técnica que permite evaluar el rendimiento del modelo de manera más robusta.
\begin{itemize}
	\item \textbf{\textit{K-Fold Cross-Validation}}: En la validación cruzada \textit{K-Fold}, el conjunto de datos se divide en $k$ pliegues (\textit{folds}). El modelo se entrena $k$ veces, cada vez utilizando $k-1$ pliegues para el entrenamiento y el pliegue restante para la prueba. El rendimiento final del modelo se obtiene promediando los resultados de las $k$ iteraciones.
	\item \textbf{\textit{Stratified K-Fold Cross-Validation}}: Este método es similar a \textit{K-Fold}, pero asegura que cada pliegue tenga una distribución similar de la variable objetivo. Esto es especialmente útil en conjuntos de datos con desequilibrio de clases.
\end{itemize}

\subsection{\textit{Bootstrap}}
El \textit{Bootstrap} es una técnica de remuestreo que estabiliza el modelo. Implica seleccionar un tamaño de muestra (generalmente igual al tamaño del conjunto de datos original), y luego seleccionar aleatoriamente puntos de datos con reemplazo para crear la muestra bootstrap. El modelo se entrena en esta muestra y se evalúa en los puntos de datos que no se incluyeron en la muestra (conocidos como muestras fuera de bolsa). Esto permite obtener una estimación robusta del rendimiento del modelo y ayuda a mitigar el sobreajuste. Esta técnica se utiliza dentro de los ensembles como ya se ha comentado en la sección anterior.

\subsection{Matriz de Confusión}

Para cada predicción de un modelo de clasificación, se puede construir una matriz de confusión que demuestra el número de casos de prueba correctamente e incorrectamente clasificados.

La matriz de confusión se ve de la siguiente manera (considerando que 1 es Positivo y 0 es Negativo para las clases objetivo):

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		& \textbf{Actual 0} & \textbf{Actual 1} \\ \hline
		\textbf{Predicted 0} & True Negatives (TN) & False Negatives (FN) \\ \hline
		\textbf{Predicted 1} & False Positives (FP) & True Positives (TP) \\ \hline
	\end{tabular}
	\caption{Matriz de Confusión}
\end{table}

\begin{itemize}
	\item \textbf{TN}: Número de casos negativos clasificados correctamente.
	\item \textbf{TP}: Número de casos positivos clasificados correctamente.
	\item \textbf{FN}: Número de casos positivos incorrectamente clasificados como negativos.
	\item \textbf{FP}: Número de casos negativos incorrectamente clasificados como positivos.
\end{itemize}

\subsubsection{Exactitud (Accuracy)}

La exactitud es la métrica más simple y se puede definir como el número de casos de prueba correctamente clasificados dividido por el número total de casos de prueba.

\[
\text{Exactitud} = \frac{TP + TN}{TP + TN + FP + FN}
\]

Sin embargo, no es muy útil para conjuntos de datos desequilibrados. Por ejemplo, en la detección de fraudes, si la proporción de fraude a no fraude es 1:99, la exactitud no sería un buen indicador del rendimiento del modelo.

\subsubsection{Precisión (Precision)}

La precisión es la métrica utilizada para identificar la corrección de la clasificación positiva.

\[
\text{Precisión} = \frac{TP}{TP + FP}
\]

Una mayor precisión significa una mejor capacidad del modelo para clasificar correctamente la clase positiva.

\subsubsection{Recall}

El recall nos dice el número de casos positivos correctamente identificados del número total de casos positivos.

\[
\text{Recall} = \frac{TP}{TP + FN}
\]

Un alto valor de recall indica que se identificaron muchos casos de fraude del total de fraudes.

\subsubsection{F1 Score}

El F1 Score es la media armónica del Recall y la Precisión, y equilibra las fortalezas de cada una.

\[
F1 = 2 \cdot \frac{\text{Precisión} \cdot \text{Recall}}{\text{Precisión} + \text{Recall}}
\]

Es útil en casos donde tanto el recall como la precisión son valiosos.

\subsubsection{AUC-ROC}

La curva ROC (\textit{Receiver Operating Characteristics}) es una gráfica de la tasa de verdaderos positivos (recall) contra la tasa de falsos positivos. El área bajo la curva (AUC-ROC) mide el rendimiento del modelo; cuanto mayor es el área, mejor es el rendimiento del modelo. Si la curva está cerca del eje diagonal (45 grados), sugiere que el modelo está prediciendo de manera aleatoria.
\imagen{../img/memoria/curvaROC.png}{Curva AUC-ROC.}{0.4}

